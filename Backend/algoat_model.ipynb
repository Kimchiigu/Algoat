{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 64)           640000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,509\n",
      "Trainable params: 677,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.6059 - accuracy: 0.2500 - val_loss: 1.6223 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.5956 - accuracy: 0.2500 - val_loss: 1.6332 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 1.5866 - accuracy: 0.2500 - val_loss: 1.6464 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.5770 - accuracy: 0.2500 - val_loss: 1.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.5666 - accuracy: 0.2500 - val_loss: 1.6825 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 1.5549 - accuracy: 0.2500 - val_loss: 1.7069 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 1.5418 - accuracy: 0.2500 - val_loss: 1.7379 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 1.5271 - accuracy: 0.2500 - val_loss: 1.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.5103 - accuracy: 0.2500 - val_loss: 1.8384 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.4907 - accuracy: 0.2500 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 1.5601 - accuracy: 0.2000\n",
      "Loss: 1.560102105140686\n",
      "Accuracy: 0.20000000298023224\n",
      "1/1 [==============================] - 1s 548ms/step\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('it_problems.csv')\n",
    "\n",
    "# Tokenize the problem descriptions\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['problem_description'])\n",
    "sequences = tokenizer.texts_to_sequences(df['problem_description'])\n",
    "\n",
    "# Pad the sequences to ensure uniform input length\n",
    "x_data = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=200)\n",
    "\n",
    "# Convert the solutions to categorical data\n",
    "y_data = pd.get_dummies(df['solution']).values\n",
    "\n",
    "# Build the model\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(input_dim=10000, output_dim=64, input_length=200),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(y_data.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_data, y_data, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_data, y_data)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "new_problems = [\"Example problem description\"]\n",
    "new_sequences = tokenizer.texts_to_sequences(new_problems)\n",
    "new_padded = keras.preprocessing.sequence.pad_sequences(new_sequences, maxlen=200)\n",
    "\n",
    "predictions = model.predict(new_padded)\n",
    "predicted_solution = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(predicted_solution)\n",
    "\n",
    "# Save the model\n",
    "model.save('it_problem_solver_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    'problem_description': [\n",
    "        \"How to fix a '404 Not Found' error?\",\n",
    "        \"How to recover a lost password on Windows?\",\n",
    "        \"How to install Python on Linux?\",\n",
    "        \"How to set up a virtual environment in Python?\",\n",
    "        \"How to resolve a 'Connection refused' error in a web server?\"\n",
    "    ],\n",
    "    'solution': [\n",
    "        \"Check if the URL is correct or if the page has been moved.\",\n",
    "        \"Use the password reset feature on the login screen.\",\n",
    "        \"Use the package manager to install Python, e.g., `sudo apt-get install python3`.\",\n",
    "        \"Use `venv` or `virtualenv` to create an isolated environment.\",\n",
    "        \"Check if the web server is running and if the firewall settings are correct.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('it_problems.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the IT Problem-Solving Game!\n",
      "1. Start Game\n",
      "2. Exit\n",
      "\n",
      "Question:  How to recover a lost password on Windows?\n",
      "1/1 [==============================] - 1s 767ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Player 2 wins!\n",
      "Welcome to the IT Problem-Solving Game!\n",
      "1. Start Game\n",
      "2. Exit\n",
      "Thanks for playing!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the model\n",
    "model = load_model('it_problem_solver_model.h5')\n",
    "\n",
    "# Load the dataset for tokenization\n",
    "df = pd.read_csv('it_problems.csv')\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(df['problem_description'])\n",
    "\n",
    "# Function to display the menu\n",
    "def display_menu():\n",
    "    print(\"Welcome to the IT Problem-Solving Game!\")\n",
    "    print(\"1. Start Game\")\n",
    "    print(\"2. Exit\")\n",
    "    choice = input(\"Enter your choice: \")\n",
    "    return choice\n",
    "\n",
    "# Function to ask questions to players\n",
    "def ask_question(question):\n",
    "    print(\"\\nQuestion: \", question)\n",
    "    answer1 = input(\"Player 1, your answer: \")\n",
    "    answer2 = input(\"Player 2, your answer: \")\n",
    "    return answer1, answer2\n",
    "\n",
    "# Function to evaluate answers with the AI model\n",
    "def evaluate_with_ai(answer1, answer2, question):\n",
    "    # Tokenize and pad the answers for the model\n",
    "    sequences1 = tokenizer.texts_to_sequences([answer1])\n",
    "    padded_answer1 = pad_sequences(sequences1, maxlen=200)\n",
    "    sequences2 = tokenizer.texts_to_sequences([answer2])\n",
    "    padded_answer2 = pad_sequences(sequences2, maxlen=200)\n",
    "\n",
    "    # Predict the relevance of the answers\n",
    "    prediction1 = model.predict(padded_answer1)[0]\n",
    "    prediction2 = model.predict(padded_answer2)[0]\n",
    "\n",
    "    # Compare the predictions\n",
    "    score1 = max(prediction1)\n",
    "    score2 = max(prediction2)\n",
    "\n",
    "    if score1 > score2:\n",
    "        return \"Player 1 wins!\"\n",
    "    elif score2 > score1:\n",
    "        return \"Player 2 wins!\"\n",
    "    else:\n",
    "        return \"It's a tie!\"\n",
    "\n",
    "# Main function to run the game\n",
    "def main():\n",
    "    while True:\n",
    "        choice = display_menu()\n",
    "        if choice == '1':\n",
    "            # Select a random question from the dataset\n",
    "            question_row = df.sample(n=1).iloc[0]\n",
    "            question = question_row['problem_description']\n",
    "            \n",
    "            # Ask the question and get answers\n",
    "            answer1, answer2 = ask_question(question)\n",
    "            \n",
    "            # Evaluate answers with the AI model and display results\n",
    "            result = evaluate_with_ai(answer1, answer2, question)\n",
    "            print(result)\n",
    "        elif choice == '2':\n",
    "            print(\"Thanks for playing!\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
