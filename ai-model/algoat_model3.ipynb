{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load BERT model and tokenizer for text embedding\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from rake_nltk import Rake\n",
    "\n",
    "# Load BERT model and tokenizer for text embedding\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load Sentence-BERT model for context analysis\n",
    "sbert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Initialize RAKE for keyword extraction\n",
    "rake = Rake()\n",
    "\n",
    "def encode_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def encode_context(text):\n",
    "    return sbert_model.encode(text)\n",
    "\n",
    "def extract_keywords(text):\n",
    "    rake.extract_keywords_from_text(text)\n",
    "    keywords = rake.get_ranked_phrases()\n",
    "    return \" \".join(keywords)\n",
    "\n",
    "# Load dataset from text file\n",
    "file_path = '/Dataset/What is a Binary Tree.txt'  # Replace with your actual file path\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process the dataset\n",
    "data = []\n",
    "for line in lines:\n",
    "    line = line.strip()\n",
    "    if line:  # Ensure line is not empty\n",
    "        data.append({'text': line, 'context': line})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# User input\n",
    "user_input = \"Binary trees are used in data structures.\"\n",
    "\n",
    "# Extract context from user input\n",
    "user_context = extract_keywords(user_input)\n",
    "\n",
    "# Encode dataset texts and user input\n",
    "df['text_embedding'] = df['text'].apply(encode_text)\n",
    "user_text_embedding = encode_text(user_input)\n",
    "\n",
    "# Encode dataset contexts and user context\n",
    "df['context_embedding'] = df['context'].apply(encode_context)\n",
    "user_context_embedding = encode_context(user_context)\n",
    "\n",
    "# Calculate similarity scores for text\n",
    "df['text_similarity'] = df['text_embedding'].apply(lambda x: cosine_similarity([x], [user_text_embedding]).item())\n",
    "\n",
    "# Calculate similarity scores for context\n",
    "df['context_similarity'] = df['context_embedding'].apply(lambda x: cosine_similarity([x], [user_context_embedding]).item())\n",
    "\n",
    "# Combine scores\n",
    "df['final_score'] = (df['text_similarity'] + df['context_similarity']) / 2\n",
    "\n",
    "# Display results\n",
    "print(df[['text', 'text_similarity', 'context_similarity', 'final_score']].sort_values(by='final_score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from rake-nltk) (3.8.1)\n",
      "Requirement already satisfied: click in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.4)\n",
      "Requirement already satisfied: joblib in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
      "Requirement already satisfied: colorama in d:\\software\\environments\\deep_learning\\environments\\deep_learning\\lib\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake-nltk) (0.4.6)\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install rake-nltk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
